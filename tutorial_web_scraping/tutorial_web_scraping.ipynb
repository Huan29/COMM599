{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Tutorial\n",
    "\n",
    "In this tutorial, we will be learning how to scrape data from an HTML page. Note that different websites will have different policies regarding scraping. \n",
    "\n",
    "We will be scraping data that is provided by the Stanford Open Policing Project. They have compiled and released traffic stop data from almost all states in the U.S.\n",
    "\n",
    "https://openpolicing.stanford.edu/\n",
    "\n",
    "The data itself can be found here:\n",
    "\n",
    "https://openpolicing.stanford.edu/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html, etree\n",
    "import requests\n",
    "import wget\n",
    "import pdb\n",
    "import argparse\n",
    "import time\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPP_URL = \"https://openpolicing.stanford.edu/data/\"\n",
    "OPP_HTML = \"opp_root.html\"\n",
    "OPP_DATA_ROOT = \"data/\"\n",
    "OPP_DL_CITIES = \"opp_downloaded_cities.txt\"\n",
    "INITIAL_URL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial url and save to file\n",
    "if INITIAL_URL: \n",
    "    with open (OPP_HTML, \"w\") as f:\n",
    "        data = requests.get(OPP_URL)\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a html parser instance\n",
    "parser = etree.HTMLParser()\n",
    "\n",
    "# open the file to start parsing\n",
    "with open(OPP_HTML, \"r\") as f, open (OPP_DL_CITIES, \"w\") as dl_city_list: \n",
    "    tree = etree.parse(f, parser)\n",
    "\n",
    "    # find all the states listed \n",
    "    states = tree.xpath(\".//tbody\")\n",
    "\n",
    "    # go through each state in the list\n",
    "    for state in states: \n",
    "        state_elem = state.xpath(\".//tr\")\n",
    "\n",
    "        # state title contained in first list element, other tr elements are cities \n",
    "        # print the state name \n",
    "        state_name = state_elem[0].xpath(\".//td\")[0].text\n",
    "        print (\"state name \", state_name)\n",
    "\n",
    "        # need to ignore the first city in the list, since it's the state name\n",
    "        # so we skip the first element\n",
    "        cities = iter(state_elem)\n",
    "        next(cities)\n",
    "\n",
    "        for city in cities: \n",
    "            # find the name of the city first \n",
    "            city_name_elem = city.xpath(\".//td[contains(@data-title, 'State')]\")[0]\n",
    "            city_name = city_name_elem.xpath(\".//span\")[0].text\n",
    "            print(city_name)\n",
    "\n",
    "            # find the download link for this file\n",
    "            city_csv_url = city.xpath(\".//td[contains(@data-title, 'Download')]\")[0].xpath(\".//a[contains(@title,'Download data as CSV')]/@href\")\n",
    "            print (city_csv_url[0])\n",
    "\n",
    "            # we need to check for the existance of certain attributes \n",
    "            # (we want driver age, citation issued, warning issued, arrest made)\n",
    "            check_attribs = [\"Driver age\", \"Citation issued\", \"Warning issued\", \"Arrest made\"]\n",
    "            # assume we want to download this file unless told otherwise\n",
    "            to_download = True\n",
    "            for attrib in check_attribs:\n",
    "                print (attrib)\n",
    "                # check to see if attribute has a child (indicating that this attribute is present in data)\n",
    "                attrib_elem = city.xpath(\".//td[contains(@data-title, '%s')]\" %(attrib))\n",
    "\n",
    "                attrib_elem_des = attrib_elem[0].xpath(\".//descendant::*\")\n",
    "                # if the attribute does not have any children, we don't want to download this file\n",
    "                if not attrib_elem_des:\n",
    "                    to_download = False\n",
    "                    \n",
    "            # if we want to download this file, download and write city name to file\n",
    "            if to_download:\n",
    "                # make directory for state\n",
    "                os.makedirs(OPP_DATA_ROOT+state_name, exist_ok = True)\n",
    "                \n",
    "                # try to download file and print error if unable to \n",
    "                try: \n",
    "                    wget.download(city_csv_url[0], OPP_DATA_ROOT+state_name)\n",
    "                    time.sleep(10)\n",
    "                except: \n",
    "                    print (\"couldn't download the file \", city_csv_url[0])\n",
    "                dl_city_list.write(state_name + \"_\" + city_name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
